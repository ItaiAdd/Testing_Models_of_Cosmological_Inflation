{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import optuna\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3249c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining E-model potential and derivative of potential\n",
    "\n",
    "def f_Emod(Y, alpha):\n",
    "    return (1 - np.exp(-np.sqrt(2/(3*alpha))*Y))**2\n",
    "    \n",
    "def df_Emod(Y, alpha):\n",
    "    return 2*np.sqrt(2/(3*alpha))*(1 - np.exp(-np.sqrt(2/(3*alpha))*Y))*np.exp(-np.sqrt(2/(3*alpha))*Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Defining T-model-1 potential and derivative of potential\n",
    "\n",
    "def f_Tmod1(Y, alpha):\n",
    "    return (np.tanh(Y/np.sqrt(6*alpha)))**2\n",
    "    \n",
    "def df_Tmod1(Y, alpha):\n",
    "    return (2/np.sqrt(6*alpha))*np.tanh(Y/np.sqrt(6*alpha))/(np.cosh(Y/np.sqrt(6*alpha)))**2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Defining T-model-2 potential and derivative of potential\n",
    "\n",
    "def f_Tmod2(Y, alpha):\n",
    "    return (np.tanh(Y/np.sqrt(6*alpha)))**4\n",
    "    \n",
    "def df_Tmod2(Y, alpha):\n",
    "    return (4/np.sqrt(6*alpha))*((np.tanh(Y/np.sqrt(6*alpha)))**3)/((np.cosh(Y/np.sqrt(6*alpha)))**2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Defining function for the analytic approximations for T-model-1 and T-model-2 predictions\n",
    "\n",
    "def analytic_approx(N, n, a):\n",
    "    g = np.sqrt(3*a*(4*n**2 + 3*a))\n",
    "    r = 12*a/(N**2 + N*g/(2*n) +3*a/4)\n",
    "    ns = (1 - 2/N -3*a/(4*N**2) + g*(1-1/N)/(2*n*N))/(1 + g/(2*n*N) + 3*a/(4*N**2))\n",
    "    return ns, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9617557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main prediction code, it takes as its inputs:\n",
    "\n",
    "#                             alpha        :   parameter for the potential and its derivative\n",
    "#                             k_piv        :   pivot scale we want to evaluate the predictions at\n",
    "#                             rh_duration  :   duration of reheating in e-folds\n",
    "#                             f            :   potential (without energy scale prefactor V0)\n",
    "#                             df           :   derivative of potential (without energy scale prefactor V0)\n",
    "\n",
    "\n",
    "def predict_ns_r(alpha, k_piv, rh_duration, f, df):\n",
    "\n",
    "    V0 = 2.099e-9\n",
    "\n",
    "    \n",
    "    #Klein-Gordon equation as first-order system    \n",
    "    def KG_system(t, y):\n",
    "        return [y[1], -(3 - 0.5*y[1]**2)*y[1] - df(y[0],alpha)/((f(y[0], alpha)/(3 - 0.5*(y[1]**2))))]\n",
    "\n",
    "    \n",
    "    \n",
    "    #Slow-roll approximation of dphi/dN    \n",
    "    def dphidN(t, y):\n",
    "        return -df(y, alpha)/f(y, alpha)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Function to get slow-roll initial conditions\n",
    "    def get_SR_ICs(phi0):\n",
    "        return [phi0, -df(phi0, alpha)/f(phi0, alpha)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Initial search for field value where first Hubble slow-roll parameter is equal to or greater than 1\n",
    "    phi_test_range = np.linspace(0.01, 20, 10000)\n",
    "    ep_tests = 0.5*(df(phi_test_range, alpha)/f(phi_test_range, alpha))**2\n",
    "    diff = np.abs(1 - ep_tests)\n",
    "    phi_end_ind = diff.argmin()\n",
    "    phi_end = phi_test_range[phi_end_ind]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Solving backwards to find initial field value\n",
    "    N = np.linspace(0, -90, 10000)\n",
    "    sol_init = solve_ivp(fun = dphidN,\n",
    "                            t_span=[0,N[-1]],\n",
    "                            t_eval = N,\n",
    "                            y0= [phi_end]\n",
    "                            )\n",
    "    \n",
    "    \n",
    "    \n",
    "    phi_i = sol_init.y[0][-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Full solution with slow-roll initial conditions and Radau method. This is what all subsequent\n",
    "    #quantities are calculated from.\n",
    "    N = np.linspace(0, 100, 10000)\n",
    "    sol = solve_ivp(fun = KG_system,\n",
    "                            t_span=[0,N[-1]],\n",
    "                            t_eval = N,\n",
    "                            y0= get_SR_ICs(phi_i),\n",
    "                            method='Radau'\n",
    "                            )\n",
    "    \n",
    "\n",
    "    phi = sol.y[0]\n",
    "    phid = sol.y[1]\n",
    "    \n",
    "    \n",
    "    #Computes the first Hubble slow-roll parameter\n",
    "    epsilon = 0.5*phid**2\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Finding the end of inflation and what we have defined as the end of slow roll in terms of epsilon\n",
    "    ep_end = np.where(epsilon >= 1)[0][0] \n",
    "    ep_end_SR = np.where(epsilon >= 0.001)[0][0]\n",
    "\n",
    "    \n",
    "    \n",
    "    #Computing the square of the Hubble parameter, field acceleration and second Hubble slow-roll parameter\n",
    "    H2 = V0*f(phi, alpha)/(3 - 0.5*(phid**2))\n",
    "    phidd = -(3 - 0.5*phid**2)*phid - df(phi, alpha)/(f(phi, alpha)/(3 - 0.5*(phid**2)))\n",
    "    eta = 2*phidd/phid\n",
    "\n",
    "    #Finding what we have defined as the end of slow roll in terms of the second Hubble slow-roll parameter \n",
    "    et_end_SR = np.where(np.abs(eta) >= 0.1)[0][0]\n",
    "    \n",
    "    \n",
    "    #Computes the energy density of the field along with the time step where the different scales exit the horizon\n",
    "    #using the initial guess for the energy scale V0. Also computes slow-roll scalar power spectrum.\n",
    "    density = 0.5*H2*phid**2 + V0*f(phi, alpha)\n",
    "    Ne = N[ep_end] - N[:ep_end]\n",
    "    k = np.exp(67 - Ne + 0.25*np.log((V0*f(phi[:ep_end], alpha))**2) - 0.25*np.log(density[ep_end]) - np.log(2997.92) - np.log(1000)/12- rh_duration/4)*0.6736\n",
    "    P_spec = H2[:ep_end]/(8*(np.pi**2)*epsilon[:ep_end])\n",
    "\n",
    "    V0_error = []\n",
    "    V0_trace = []\n",
    "    \n",
    "    \n",
    "    #Finds the timestep where the scale closest to thepivot scale exits the horizon\n",
    "    diff = np.abs(k - k_piv)\n",
    "    k_piv_index = diff.argmin()\n",
    "    Planck_As = 2.099e-9\n",
    "    error = P_spec[k_piv_index]/Planck_As\n",
    "\n",
    "    \n",
    "    V0_trace.append(V0)\n",
    "    V0_error.append(error)\n",
    "    \n",
    "    \n",
    "    #Loop to iteratively adjust the V0 to match Planck_As at the pivot scale.\n",
    "    while np.around(error, 3) != 1:\n",
    "            \n",
    "            if np.around(error, 3) > 1:\n",
    "                V0 = V0*0.99\n",
    "\n",
    "                H2 = V0*f(phi, alpha)/(3 - 0.5*(phid**2))\n",
    "                density = 0.5*H2*(phid)**2 + V0*f(phi, alpha)\n",
    "                k = np.exp(67 - Ne + 0.25*np.log((V0*f(phi[:ep_end], alpha))**2) - 0.25*np.log(density[ep_end]) - np.log(2997.92) - np.log(1000)/12- rh_duration/4)*0.6736\n",
    "                P_spec = H2[ep_end]/(8*(np.pi**2)*epsilon[:ep_end])\n",
    "\n",
    "\n",
    "                diff = np.abs(k - k_piv)\n",
    "                k_piv_index = diff.argmin()\n",
    "                error = P_spec[k_piv_index]/Planck_As\n",
    "                \n",
    "                \n",
    "            elif np.around(error, 3) < 1:\n",
    "                V0 = V0*1.01\n",
    "\n",
    "\n",
    "                H2 = V0*f(phi, alpha)/(3 - 0.5*(phid**2))\n",
    "                density = 0.5*H2*(phid)**2 + V0*f(phi, alpha)\n",
    "                k = np.exp(67 - Ne + 0.25*np.log((V0*f(phi[:ep_end], alpha))**2) - 0.25*np.log(density[ep_end]) - np.log(2997.92) - np.log(1000)/12- rh_duration/4)*0.6736\n",
    "                P_spec = H2[:ep_end]/(8*(np.pi**2)*epsilon[:ep_end])\n",
    "                \n",
    "        \n",
    "                diff = np.abs(k - k_piv)\n",
    "                k_piv_index = diff.argmin()\n",
    "                error = P_spec[k_piv_index]/Planck_As\n",
    "\n",
    "            V0_trace.append(V0)\n",
    "            V0_error.append(error)\n",
    "\n",
    "\n",
    "    #Calculates ns and r using first-order expressions\n",
    "    ns = 1 - 2*epsilon[k_piv_index] - eta[k_piv_index]\n",
    "    r = 16*epsilon[k_piv_index]\n",
    "\n",
    "    return ns, r, Ne, k, P_spec, epsilon, eta, ep_end, k_piv_index, V0_trace, V0_error, phi, phid, phidd, H2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5253194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_trace=[]\n",
    "rh_duration_trace=[]\n",
    "loss_trace=[]\n",
    "ns_trace=[]\n",
    "r_trace=[]\n",
    "targets=[]\n",
    "best_alpha = []\n",
    "bestLoss = []\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(ns_target, r_target, alpha, rh_duration):\n",
    "    # Perform the calculations based on alpha and rh_duration\n",
    "    ns, r, Ne, k, P_spec, epsilon, eta, ep_end, k_piv_index, V0_trace, V0_error, phi, phid, phidd, H2 = predict_ns_r(alpha, 0.05, rh_duration, f=f_Emod, df=df_Emod)\n",
    "    ns_trace.append(ns)\n",
    "    r_trace.append(r)\n",
    "    # Calculate the mean squared error between the target values and the predictions\n",
    "    mse_ns = 0.5*(ns - ns_target)**2\n",
    "    mse_r = 0.5*(r - r_target)**2\n",
    "    \n",
    "    # Combine the MSEs into an overall loss\n",
    "    loss = mse_ns + mse_r\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the search space for alpha and rh_duration\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 100)\n",
    "    \n",
    "    \n",
    "    alpha_trace.append(alpha)\n",
    "    rh_duration_trace.append(rh_duration)\n",
    "    \n",
    "    ns_target = 9.6526352E-01\n",
    "    r_target = 1.6233650E-02\n",
    "    \n",
    "    # Calculate the loss using the defined loss function\n",
    "    loss = loss_function(ns_target, r_target, alpha, rh_duration)\n",
    "    loss_trace.append(loss)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "for duration in tqdm([0,15,30,40]):\n",
    "    rh_duration = duration\n",
    "    # Create a new Optuna study\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "\n",
    "    # Run the optimization\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    # Get the best parameter values and loss\n",
    "    best_params = study.best_params\n",
    "    best_loss = study.best_value\n",
    "\n",
    "    best_alpha.append(best_params)\n",
    "    bestLoss.append(best_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50130da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha_final = []\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    upper_lim = best_alpha_1 + 2\n",
    "    if best_alpha_1 <=2:\n",
    "        lower_lim = 0.01\n",
    "    else:\n",
    "        lower_lim = best_alpha_1 -2\n",
    "    \n",
    "\n",
    "\n",
    "    alpha = trial.suggest_float('alpha', lower_lim, upper_lim)\n",
    "\n",
    "    \n",
    "    alpha_trace.append(alpha)\n",
    "    rh_duration_trace.append(rh_duration)\n",
    "    \n",
    "    ns_target = 9.6526352E-01\n",
    "    r_target = 1.6233650E-02\n",
    "    \n",
    "    \n",
    "    loss = loss_function(ns_target, r_target, alpha, rh_duration)\n",
    "    loss_trace.append(loss)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "\n",
    "for i, duration in enumerate(tqdm([0,15,30,40])):\n",
    "    rh_duration = duration\n",
    "    best_alpha_1 = best_alpha[i]['alpha']\n",
    "    # Create a new Optuna study\n",
    "    study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "\n",
    "    # Run the optimization\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    # Get the best parameter values and loss\n",
    "    best_params = study.best_params\n",
    "    best_loss = study.best_value\n",
    "\n",
    "    best_alpha_final.append(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
